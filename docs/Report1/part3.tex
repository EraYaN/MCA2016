\section{Configuration}
After a lot of experimentation the configuration file included with this report was found. In this section that configuration, the compiler flags and the process that led to the final result's will be discussed. Taking the amount of execution cycles shown in the ta.log file as the most important metric for performance (as advised), results in this section will often be compared to the original amount of execution cycles for the benchmarks (compiled with optimization level 3). These were 724703 and 509595 for engine and fir respectively.

\subsection{Clusters}
One of the first experiments was to see if there would be a significant difference between using the 1 cluster and 2 cluster example configurations. Confusingly, using an extra cluster seemed to barely have any effect on the performance of engine and even seemed to make fir slower. Taking a look at the assembly files for both revealed that fir barely used the second cluster. The intercluster move operations may have been more taxing on the performance than the added benefit of using an extra cluster was making up for it. Unsurprisingly, significantly increasing the resources for both clusters did improve the performance. But still, while the performance increase for engine was pretty good (decreasing by as much as 60000 cycles of the original 725000 execution cycles), the performance of fir was barely impacted. A quick look in the fir.s assembly file confirmed that the second cluster was barely used. This is when it was decided that the processor was going to be designed using 1 cluster. The large amount of extra resources was not worth the increase in performance, considering that fir was barely affected. This also meant that \textbf{CopySrc} and \textbf{CopyDst} could be set to zero because no intercluster communication was needed.

\subsection{Issue width, ALU, multiply}
Considering only one cluster was used, increasing the issue width was one of the first priorities so more instruction level parallelism could be achieved. Increasing the issue width to 8 and giving the processors more than enough resources in the ALU and multiply departments provided a significant improvement in performance for engine, and a slight improvement for fir. A look into the assembly files for both benchmarks did show that the bundles on average had become significantly bigger, but the full issue width was barely used making a smaller issue width of 4 also a sensible choice, slightly decreasing performance but saving a lot on resources.

Both programs seemed to barely need multiplication so the amount of multiply syllables per cycle \textbf{Mpy} was set to 1. The amount of ALU syllables per cycle was kept high with \textbf{Alu} being set to 4 to allow the especially addition heavy engine (and somewhat less so fir) to keep it's execution cycles low.

\subsection{Memory and registers}
Considering that especially fir showed a lot of memory operations this is also an important part of the configuration file for performance. When the amount of connections to the data cache was put to 8 for both stores and loads up to 4 store and load syllables were showing up per bundle in the fir.s assembly file. Unfortunately this still accounted for only about 1000 execution cycles and engine didn't profit from it at all. Keeping that in mind it was decided to stick with \textbf{MemLoad} and \textbf{MemStore} both on 4 and the amount of allowed syllables per cycle (\textbf{Memory}) to 2.

A quick look at the assembly for both fir and engine showed that both (barely) didn't use r registers above 25 and b registers above 4. Therefore it was a quick decision to set \textbf{\$r} to 25 and \textbf{\$b} to 4.

\subsection{Compiler flags}
After editing the configuration file according as described above, the performance increase was not overwhelming. With engine at 652606 and fir at 506946 execution cycles it seemed that a better performance should still be possible. Therefore, a couple of compiler flags were used to increase performance. \textbf{-O4} was used in stead of optimization level 3 used in the lab manual but it didn't seem to have much effect. A very effective flag was \textbf{-fexpand-div}. \cref{todo} todo already showed that the function \_i\_div was used a lot in engine so using in-line assembly for these divisions was an obvious choice. Another very effective flag was \textbf{-autoinline}. Replacing function calls with the functions themselves it saved thousands of cycles for both engine and fir.

\section{Conclusion}
